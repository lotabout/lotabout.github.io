<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=" id=&quot;背景&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;
&lt;p&gt;看到 plantegg 大佬的文章 &lt;a href=&quot;https://plantegg.github.io/2020/11/17/MySQL%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AF%BC%E8%87%B4%E7%9A%84%E5%BB%B6%E6%97%B6%E5%8D%A1%E9%A1%BF%E6%8E%92%E6%9F%A5/&quot;&gt;MySQL线程池导致的延时卡顿排查&lt;/a&gt;
中提到 MySQL 线程池中 oversubscribe 的行为。也看到有小伙伴&lt;a href=&quot;https://github.com/wych42&quot;&gt;wych42&lt;/a&gt;在&lt;a href=&quot;https://gist.github.com/wych42/87df731da394a14d926c87f51fa9469d&quot;&gt;尝试复现&lt;/a&gt;文章里提到的现象。"><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/noise.css"><title>Percona 线程池行为验证 | 三点水</title><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><meta name="generator" content="Hexo 7.1.1"></head><body><article class="wrapper"><div class="post-main"><div class="nav"><nav class="container"><a class="sidebar-nav-item active" href="/">Home</a><a class="sidebar-nav-item" href="/books">Books</a><a class="sidebar-nav-item" href="/about">About</a></nav><div class="container post-meta"><div class="post-tags"><a class="post-tag-noise-link" href="/tags/case-study/" rel="tag">case study</a><a class="post-tag-noise-link" href="/tags/mysql/" rel="tag">mysql</a><a class="post-tag-noise-link" href="/tags/percona/" rel="tag">percona</a><a class="post-tag-noise-link" href="/tags/thread-pool/" rel="tag">thread pool</a></div><div class="post-time">2023-05-26</div></div></div><div class="container post-header"><h1>Percona 线程池行为验证</h1></div><div class="container post-toc"><details class="toc"><summary class="toc-accordion">Table of Contents</summary><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">1.</span> <span class="toc-text">背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%81%87%E6%83%B3%E7%9A%84-oversubscribe-%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.</span> <span class="toc-text">假想的 oversubscribe 模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%AE%E5%BC%82%E4%B8%80%EF%BC%9A%E8%80%97%E6%97%B6%E4%B8%8D%E7%A8%B3%E5%AE%9A"><span class="toc-number">3.</span> <span class="toc-text">差异一：耗时不稳定</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#percona-thread-group-%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">Percona thread group 模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%AE%E5%BC%82%E4%B8%80%E8%A7%A3%E9%87%8A"><span class="toc-number">5.</span> <span class="toc-text">差异一解释</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%AE%E5%BC%82%E4%B8%80%E8%A1%A5%E5%85%85-case%EF%BC%9A%E9%AB%98%E4%BC%98%E9%98%9F%E5%88%97%E4%B8%8D%E5%8F%97%E8%A7%84%E5%88%99-4-2-%E9%99%90%E5%88%B6"><span class="toc-number">6.</span> <span class="toc-text">差异一补充 case：高优队列不受规则 4.2 限制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%AE%E5%BC%82%E4%BA%8C%EF%BC%9Aselect-sleep-%E5%8F%AF%E8%83%BD%E4%B8%8D%E6%98%AF%E5%A5%BD%E8%B4%9F%E8%BD%BD"><span class="toc-number">7.</span> <span class="toc-text">差异二：SELECT SLEEP 可能不是好负载</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%BD%E4%B8%8D%E8%83%BD%E7%AE%80%E5%8C%96%EF%BC%9F"><span class="toc-number">8.</span> <span class="toc-text">能不能简化？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">9.</span> <span class="toc-text">参考</span></a></li></ol></details></div><div class="container post-content"><h2 id="背景"><a class="header-anchor" href="#背景"></a>背景</h2>
<p>看到 plantegg 大佬的文章 <a href="https://plantegg.github.io/2020/11/17/MySQL%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AF%BC%E8%87%B4%E7%9A%84%E5%BB%B6%E6%97%B6%E5%8D%A1%E9%A1%BF%E6%8E%92%E6%9F%A5/">MySQL线程池导致的延时卡顿排查</a>
中提到 MySQL 线程池中 oversubscribe 的行为。也看到有小伙伴<a href="https://github.com/wych42">wych42</a>在<a href="https://gist.github.com/wych42/87df731da394a14d926c87f51fa9469d">尝试复现</a>文章里提到的现象。</p>
<p>自己也尝试复现（基于 Percona 8.0.29-21），但现象和 wych42 的结果有细节上的差异，引申发现自己对 Percona 线程池模型的理解有问题，记录一下。</p>
<h2 id="假想的-oversubscribe-模型"><a class="header-anchor" href="#假想的-oversubscribe-模型"></a>假想的 oversubscribe 模型</h2>
<p>我们知道 oversubscribe 是用来限制 thread group 内同时运行的线程数量的，于是猜想工作原理（类比 Java 中的 <code>ThreadPoolExecutor</code>，oversubscribe 类比
<code>corePoolSize</code>）：</p>
<ol>
<li>由 thread group 中的 listener 线程将任务从网络连接挪到 thread group 中的队列</li>
<li>在需要时创建若干个 worker 来消费队列，此时如果数量超过 oversubscribe 则停止创建</li>
<li>worker 在空闲若干时间后退出</li>
</ol>
<h2 id="差异一：耗时不稳定"><a class="header-anchor" href="#差异一：耗时不稳定"></a>差异一：耗时不稳定</h2>
<p>仿照在 wych42 的 <a href="https://gist.github.com/wych42/87df731da394a14d926c87f51fa9469d#%E6%89%A7%E8%A1%8C%E6%96%B9%E6%A1%88-1">执行方案一</a>中，设置如下：</p>
<div class="noise-code-block" style="--code-block-max-height:inherit"><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">| thread_handling                         | pool-of-threads |</span><br><span class="line">| thread_pool_high_prio_mode              | transactions    |</span><br><span class="line">| thread_pool_high_prio_tickets           | 4294967295      |</span><br><span class="line">| thread_pool_idle_timeout                | 60              |</span><br><span class="line">| thread_pool_max_threads                 | 100000          |</span><br><span class="line">| thread_pool_oversubscribe               | 1               |</span><br><span class="line">| thread_pool_size                        | 1               |</span><br><span class="line">| thread_pool_stall_limit                 | 500             |</span><br></pre></td></tr></table></figure></div>
<ul>
<li>执行SQL <code>select sleep(2)</code></li>
<li>执行并发：<code>8</code></li>
</ul>
<p>按前一节的假想模型，预期 thread group 每次有 2 个线程执行(1+oversubscribe)，结果是每批次 2 个 SQL 输出，耗时分别是 2s, 4s, 6s, 8s。</p>
<p>实测发现并不总是符合预期，各种情况都有，比如会有两批次就跑完的(4 个SQL 2s 加上
2 个 SQL 4s）：</p>
<div class="noise-code-block" style="--code-block-max-height:300px"><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">16:05:08.765+08:00: thread 0 iteration 1 start</span><br><span class="line">16:05:08.765+08:00: thread 7 iteration 1 start</span><br><span class="line">16:05:08.765+08:00: thread 3 iteration 1 start</span><br><span class="line">16:05:08.765+08:00: thread 4 iteration 1 start</span><br><span class="line">16:05:08.765+08:00: thread 1 iteration 1 start</span><br><span class="line">16:05:08.765+08:00: thread 5 iteration 1 start</span><br><span class="line">16:05:08.766+08:00: thread 2 iteration 1 start</span><br><span class="line">16:05:08.766+08:00: thread 6 iteration 1 start</span><br><span class="line">16:05:10.985+08:00: thread 4 iteration 1 took 2220 ms</span><br><span class="line">16:05:10.985+08:00: thread 0 iteration 1 took 2220 ms</span><br><span class="line">16:05:10.985+08:00: thread 3 iteration 1 took 2220 ms</span><br><span class="line">16:05:11.029+08:00: thread 5 iteration 1 took 2264 ms</span><br><span class="line">16:05:11.029+08:00: thread 7 iteration 1 took 2264 ms</span><br><span class="line">16:05:13.080+08:00: thread 6 iteration 1 took 4313 ms</span><br><span class="line">16:05:13.080+08:00: thread 1 iteration 1 took 4314 ms</span><br><span class="line">16:05:13.085+08:00: thread 2 iteration 1 took 4320 ms</span><br><span class="line">16:05:13.086+08:00: thread 2 iteration 2 start</span><br><span class="line">16:05:13.086+08:00: thread 6 iteration 2 start</span><br><span class="line">16:05:13.086+08:00: thread 5 iteration 2 start</span><br><span class="line">16:05:13.086+08:00: thread 3 iteration 2 start</span><br><span class="line">16:05:13.086+08:00: thread 1 iteration 2 start</span><br><span class="line">16:05:13.086+08:00: thread 4 iteration 2 start</span><br><span class="line">16:05:13.086+08:00: thread 0 iteration 2 start</span><br><span class="line">16:05:13.086+08:00: thread 7 iteration 2 start</span><br><span class="line">16:05:15.167+08:00: thread 6 iteration 2 took 2081 ms</span><br><span class="line">16:05:15.167+08:00: thread 1 iteration 2 took 2081 ms</span><br><span class="line">16:05:17.165+08:00: thread 2 iteration 2 took 4080 ms</span><br><span class="line">16:05:17.165+08:00: thread 3 iteration 2 took 4079 ms</span><br><span class="line">16:05:19.170+08:00: thread 5 iteration 2 took 6084 ms</span><br><span class="line">16:05:19.170+08:00: thread 4 iteration 2 took 6084 ms</span><br><span class="line">16:05:21.164+08:00: thread 0 iteration 2 took 8078 ms</span><br><span class="line">16:05:21.164+08:00: thread 7 iteration 2 took 8078 ms</span><br><span class="line">16:05:21.165+08:00: thread 1 iteration 3 start</span><br><span class="line">16:05:21.165+08:00: thread 4 iteration 3 start</span><br><span class="line">16:05:21.165+08:00: thread 7 iteration 3 start</span><br><span class="line">16:05:21.165+08:00: thread 2 iteration 3 start</span><br><span class="line">16:05:21.165+08:00: thread 3 iteration 3 start</span><br><span class="line">16:05:21.165+08:00: thread 6 iteration 3 start</span><br><span class="line">16:05:21.165+08:00: thread 5 iteration 3 start</span><br><span class="line">16:05:21.165+08:00: thread 0 iteration 3 start</span><br><span class="line">16:05:23.252+08:00: thread 6 iteration 3 took 2087 ms</span><br><span class="line">16:05:23.252+08:00: thread 7 iteration 3 took 2087 ms</span><br><span class="line">16:05:25.271+08:00: thread 2 iteration 3 took 4106 ms</span><br><span class="line">16:05:25.271+08:00: thread 4 iteration 3 took 4106 ms</span><br><span class="line">16:05:27.252+08:00: thread 3 iteration 3 took 6087 ms</span><br><span class="line">16:05:27.251+08:00: thread 1 iteration 3 took 6086 ms</span><br><span class="line">16:05:29.243+08:00: thread 0 iteration 3 took 8078 ms</span><br><span class="line">16:05:29.243+08:00: thread 5 iteration 3 took 8078 ms</span><br><span class="line">16:05:29.244+08:00: thread 5 iteration 4 start</span><br><span class="line">16:05:29.244+08:00: thread 2 iteration 4 start</span><br><span class="line">16:05:29.244+08:00: thread 6 iteration 4 start</span><br><span class="line">16:05:29.244+08:00: thread 7 iteration 4 start</span><br><span class="line">16:05:29.244+08:00: thread 4 iteration 4 start</span><br><span class="line">16:05:29.244+08:00: thread 1 iteration 4 start</span><br><span class="line">16:05:29.244+08:00: thread 3 iteration 4 start</span><br><span class="line">16:05:29.244+08:00: thread 0 iteration 4 start</span><br><span class="line">16:05:31.342+08:00: thread 7 iteration 4 took 2098 ms</span><br><span class="line">16:05:31.343+08:00: thread 5 iteration 4 took 2099 ms</span><br><span class="line">16:05:33.324+08:00: thread 2 iteration 4 took 4080 ms</span><br><span class="line">16:05:33.324+08:00: thread 1 iteration 4 took 4080 ms</span><br><span class="line">16:05:33.411+08:00: thread 3 iteration 4 took 4167 ms</span><br><span class="line">16:05:33.417+08:00: thread 6 iteration 4 took 4173 ms</span><br><span class="line">16:05:35.424+08:00: thread 0 iteration 4 took 6180 ms</span><br><span class="line">16:05:35.424+08:00: thread 4 iteration 4 took 6180 ms</span><br></pre></td></tr></table></figure></div>
<p>这说明要么是我们的假想模型有问题，要么是 Percona 实现有 BUG。那实际情况是怎么样的呢？拉代码看半天也看不出所以然，只能自行编译并加了很多 debug 日志，大概是明白了。</p>
<h2 id="percona-thread-group-模型"><a class="header-anchor" href="#percona-thread-group-模型"></a>Percona thread group 模型</h2>
<p>这里只说明 thread group 内的机制（不考虑全局的限制）。</p>
<ol>
<li>线程有两种状态：active &amp; waiting，执行 SQL 过程中阻塞则记为 waiting，如等锁或 SLEEP</li>
<li>线程的角色分成 listener 和 worker。listener 将网络上的请求挪到队列中，
worker 从队列中获取任务来执行。一些情况下 listener 会自己变成worker 执行任务，worker 发现没有 listener 时也会变成 listener</li>
<li>每个 group 内部有两个队列，高优队列和低优队列。如默认模式下，处于 XA 事务、持有表锁等情形下会被认为高优<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></li>
<li>thread_pool_oversubscribe 用来限制同时运行的线程数量，它是通过限制从队列获取任务来达到目的：
<ol>
<li>active 线程数 &gt;= 1 + oversubscribe 时 worker 不取任务，直接休眠，取任务时额外考虑下面规则</li>
<li>active + waiting 线程数 &gt; 1 + oversubscribe 时 worker 不取任务，但只限制低优队列中的任务</li>
</ol>
</li>
<li>为了防止各种假死的情况，会有专门的定时线程，检测两次执行间是否有进展，如果没有进展则会创建新的 worker（且此时规则 4.1 失效）。如 listener 变成 worker
后创建新的线程承担工作</li>
<li>worker 线程在空闲一段时间(<code>thread_pool_idle_timeout</code>)后会退出</li>
</ol>
<p>有几个推论：</p>
<ol>
<li>thread group 的线程数可能大于 1+oversubscribe。没有机制限制线程的生成</li>
<li>同时运行的任务可能会大于 1+oversubscribe。一方面 listener 变成 worker 时接任务不通过队列，因此不受限制；另一方面 waiting 的任务不参与计算规则 4.1；再者高优任务不参与计算规则 4.2.</li>
<li>即使允许执行，任务的开始时间也可能会有延迟。如当前 listener 在干活，新任务只能等定时任务生成新的 worker 来执行，运气差的，延时可能会接近
<code>2*thread_pool_stall_limit</code>。</li>
</ol>
<h2 id="差异一解释"><a class="header-anchor" href="#差异一解释"></a>差异一解释</h2>
<p>结合更新后的模型以及实际的 debug 日志，差异一解释如下：</p>
<ol>
<li><code>SELECT SLEEP</code> 语句在执行时，线程会变成 waiting 状态</li>
<li>由于 active 线程为 0, 很多代码位置上会尝试创建新的线程</li>
<li>新的 worker 线程由于规则 4.2 的限制会取不到任务，进入休眠</li>
<li>但由于某些时刻所有线程都在做任务，没有 listener，此时 worker 不休眠，而进入
listener 模式</li>
<li>进入 listener 模式的的线程在一些情况（发现有新任务且已有的队列为空）下会决定自己执行任务</li>
<li>当 listener 决定自己执行任务，它会直接从网络连接中获取任务而不经过任务队列，因此不受限制</li>
<li>listener 开始执行任务时变成 worker 角色，有可能重新触发情况 #4</li>
</ol>
<h2 id="差异一补充-case：高优队列不受规则-4-2-限制"><a class="header-anchor" href="#差异一补充-case：高优队列不受规则-4-2-限制"></a>差异一补充 case：高优队列不受规则 4.2 限制</h2>
<p>已知锁表能让事务成为高优，我们把负载改成两句 SQL：</p>
<div class="noise-code-block" style="--code-block-max-height:inherit"><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LOCK TABLES t? READ ; 这里每个线程锁不同的表</span><br><span class="line">SELECT SLEEP(2)</span><br></pre></td></tr></table></figure></div>
<p>测试的结果如下，可以看到在第一个迭代中创建了 N 个 worker，第二个迭代中每个
worker 都实际执行了任务，因此结果只有一个批次，都是 2s 左右。</p>
<div class="noise-code-block" style="--code-block-max-height:300px"><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">11:47:36.251+08:00: thread 0 iteration 0 start</span><br><span class="line">11:47:36.251+08:00: thread 7 iteration 0 start</span><br><span class="line">11:47:36.251+08:00: thread 5 iteration 0 start</span><br><span class="line">11:47:36.251+08:00: thread 2 iteration 0 start</span><br><span class="line">11:47:36.251+08:00: thread 1 iteration 0 start</span><br><span class="line">11:47:36.251+08:00: thread 6 iteration 0 start</span><br><span class="line">11:47:36.251+08:00: thread 4 iteration 0 start</span><br><span class="line">11:47:36.251+08:00: thread 3 iteration 0 start</span><br><span class="line">11:47:39.059+08:00: thread 0 iteration 0 took 2808 ms</span><br><span class="line">11:47:39.162+08:00: thread 5 iteration 0 took 2911 ms</span><br><span class="line">11:47:39.425+08:00: thread 7 iteration 0 took 3174 ms</span><br><span class="line">11:47:41.282+08:00: thread 1 iteration 0 took 5031 ms</span><br><span class="line">11:47:41.352+08:00: thread 6 iteration 0 took 5101 ms</span><br><span class="line">11:47:41.463+08:00: thread 2 iteration 0 took 5212 ms</span><br><span class="line">11:47:41.613+08:00: thread 4 iteration 0 took 5362 ms</span><br><span class="line">11:47:43.532+08:00: thread 3 iteration 0 took 7281 ms</span><br><span class="line">11:47:43.533+08:00: thread 3 iteration 1 start</span><br><span class="line">11:47:43.533+08:00: thread 5 iteration 1 start</span><br><span class="line">11:47:43.533+08:00: thread 7 iteration 1 start</span><br><span class="line">11:47:43.533+08:00: thread 0 iteration 1 start</span><br><span class="line">11:47:43.533+08:00: thread 2 iteration 1 start</span><br><span class="line">11:47:43.533+08:00: thread 4 iteration 1 start</span><br><span class="line">11:47:43.533+08:00: thread 1 iteration 1 start</span><br><span class="line">11:47:43.533+08:00: thread 6 iteration 1 start</span><br><span class="line">11:47:45.727+08:00: thread 3 iteration 1 took 2194 ms</span><br><span class="line">11:47:45.751+08:00: thread 7 iteration 1 took 2218 ms</span><br><span class="line">11:47:45.751+08:00: thread 2 iteration 1 took 2218 ms</span><br><span class="line">11:47:45.751+08:00: thread 4 iteration 1 took 2218 ms</span><br><span class="line">11:47:45.755+08:00: thread 5 iteration 1 took 2222 ms</span><br><span class="line">11:47:45.756+08:00: thread 1 iteration 1 took 2223 ms</span><br><span class="line">11:47:45.760+08:00: thread 0 iteration 1 took 2227 ms</span><br><span class="line">11:47:45.765+08:00: thread 6 iteration 1 took 2232 ms</span><br></pre></td></tr></table></figure></div>
<h2 id="差异二：select-sleep-可能不是好负载"><a class="header-anchor" href="#差异二：select-sleep-可能不是好负载"></a>差异二：SELECT SLEEP 可能不是好负载</h2>
<p>通过源码我们知道执行 SLEEP 的线程是 waiting 状态，会绕过某些 oversubscribe 的限制。我们尝试使用下面的负载：</p>
<div class="noise-code-block" style="--code-block-max-height:inherit"><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MySQL&gt; select benchmark(9999999, md5(&#x27;when will it end?&#x27;));</span><br><span class="line">1 row in set</span><br><span class="line">Time: 2.079s</span><br></pre></td></tr></table></figure></div>
<p>测试的结果就更看不出“批次”的模式了。当然由于多个任务并行执行，实际的耗时也增加了（3.8s）。</p>
<div class="noise-code-block" style="--code-block-max-height:inherit"><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">16:58:01.905+08:00: thread 2 iteration 0 start</span><br><span class="line">16:58:01.905+08:00: thread 6 iteration 0 start</span><br><span class="line">16:58:01.905+08:00: thread 1 iteration 0 start</span><br><span class="line">16:58:01.905+08:00: thread 4 iteration 0 start</span><br><span class="line">16:58:01.905+08:00: thread 7 iteration 0 start</span><br><span class="line">16:58:01.905+08:00: thread 5 iteration 0 start</span><br><span class="line">16:58:01.905+08:00: thread 3 iteration 0 start</span><br><span class="line">16:58:01.905+08:00: thread 0 iteration 0 start</span><br><span class="line">16:58:05.757+08:00: thread 0 iteration 0 took 3852 ms</span><br><span class="line">16:58:06.679+08:00: thread 5 iteration 0 took 4774 ms</span><br><span class="line">16:58:08.376+08:00: thread 1 iteration 0 took 6471 ms</span><br><span class="line">16:58:10.425+08:00: thread 2 iteration 0 took 8520 ms</span><br><span class="line">16:58:11.620+08:00: thread 6 iteration 0 took 9715 ms</span><br><span class="line">16:58:13.604+08:00: thread 4 iteration 0 took 11699 ms</span><br><span class="line">16:58:14.413+08:00: thread 3 iteration 0 took 12508 ms</span><br><span class="line">16:58:16.843+08:00: thread 7 iteration 0 took 14938 ms</span><br></pre></td></tr></table></figure></div>
<p>但是，我们预期仍是一个批次执行两个 SQL，为什么第二个请求 <code>4774ms</code> 才返回？下面我们看看在 Percona 中增加的 debug 信息，来了解内部工作的机制</p>
<div class="noise-code-block" style="--code-block-max-height:inherit"><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">   time         thread id       message</span><br><span class="line">   16:58:02.197 123145417097216 command: 3: select benchmark(9999999, md5(&#x27;when will it end?&#x27;));</span><br><span class="line">   16:58:02.206 4863544832 add connection(active: 1, waiting: 0, stalled: 0)</span><br><span class="line">① 16:58:02.899 123145390891008 check_stall #1&gt; wake_or_create(active: 1, waiting: 0, stalled: 0)</span><br><span class="line">   16:58:02.899 123145390891008 wake or create thread</span><br><span class="line">   16:58:02.899 123145390891008 thread waked (active: 1, waiting: 0, stalled: 0)</span><br><span class="line">   16:58:02.899 123145418162176 get_event &gt; after wakeup(active: 2, waiting: 0, stalled: 0)</span><br><span class="line">② 16:58:02.899 123145418162176 get_event poll (active: 2, waiting: 0, stalled: 0, oversubscribed: 1)</span><br><span class="line">   16:58:02.899 123145418162176 get_event current listener(0)</span><br><span class="line">③ 16:58:02.899 123145418162176 get_event become listener(active: 1, waiting: 0, stalled: 0)</span><br><span class="line">   16:58:02.899 123145418162176 get_event become listener get lock(active: 1, waiting: 0, stalled: 0)</span><br><span class="line">   16:58:02.899 123145418162176 listener #0(active: 1, waiting: 0, stalled: 0)</span><br><span class="line">④ 16:58:03.402 123145390891008 check_stall #2&gt; wake_or_create(active: 1, waiting: 0, stalled: 1)</span><br><span class="line">   16:58:03.402 123145390891008 wake or create thread</span><br><span class="line">   16:58:03.402 123145390891008 waked failed (active: 1, waiting: 0, stalled: 1)</span><br><span class="line">   16:58:03.402 123145390891008 throttle create worker #2(active: 1, waiting: 0, stalled: 1)</span><br><span class="line">   16:58:03.402 123145390891008 create worker called(active: 1, waiting: 0, stalled: 1)</span><br><span class="line">   16:58:03.402 123145419227136 worker main start (active: 2, waiting: 0, stalled: 1)</span><br><span class="line">   16:58:03.402 123145419227136 get_event start (active: 2, waiting: 0, stalled: 1)</span><br><span class="line">   16:58:03.402 123145419227136 get_event poll (active: 2, waiting: 0, stalled: 1, oversubscribed: 0)</span><br><span class="line">⑤ 16:58:03.402 123145419227136 queue_get #0 (active: 2, waiting: 0, stalled: 1, toomany: 0)</span><br><span class="line">   16:58:03.402 123145419227136 queue_get #2 (active: 2, waiting: 0, stalled: 1)</span><br><span class="line">   16:58:03.402 123145419227136 get_event connection = 8c148620(active: 2, waiting: 0, stalled: 1, oversubscribed: 0)</span><br><span class="line">   16:58:03.402 123145419227136 get_event end (active: 2, waiting: 0, stalled: 1)</span><br><span class="line">⑥ 16:58:03.402 123145419227136 command: 3: select benchmark(9999999, md5(&#x27;when will it end?&#x27;));</span><br></pre></td></tr></table></figure></div>
<ul>
<li>由于第一个 listener 线程执行了第一个任务，① 处 check stall 线程触发，尝试创建一个新的 worker。</li>
<li>在 ② 处，该 worker 尝试获取任务，但因为此时 active 为 2 (<code>&gt;= 1+oversubscribed=2</code>），触发了限制，因此从队列中获取不到任务。</li>
<li>接着 ③ 中，worker 发现当前没有 listener，于是自己成为 listener，但此时网络上没有数据，进入休眠。</li>
<li>④ 中 check stall 第二次唤醒，发现有 listener，但队列不为空，于是尝试唤醒或新建线程。此时没有 waiting 中的线程，于是创建新的线程。</li>
<li>⑤ 中新建的线程从队列中获取任务，虽然当前 oversubscribed，但由于状态是 stalled，于是不受规则 4.1 限制，而此时 (<code>active+waiting = 2 &lt;= 1+oversubscribed=2</code>)，也不受规则 4.2 限制，于是获取任务并执行。看到 ⑥ 中执行命令，此时距离接受到命令过去了 1s+，也因此整个请求是 4s+。</li>
</ul>
<p>这个例子给出两个信息：</p>
<ol>
<li>waiting 和 active 的负载对 thread group 调度来说是有差异的</li>
<li>由于创建线程的滞后性（由 check stall 定时线程），任务执行会有延迟，且延迟不低</li>
</ol>
<h2 id="能不能简化？"><a class="header-anchor" href="#能不能简化？"></a>能不能简化？</h2>
<p>Percona 实际的线程模型显然没有我们假想模型简单，那能不能简化呢？</p>
<p>例如为什么不用全职 listener，listener 完成不参与执行任务？这是因为直接让
listener 处理任务效率更高，listener 刚从等待网络中被唤醒，不需要从再唤醒一个
worker，减少线程切换。但 listener 擅离职守会造成后续任务的延时，因此 listener
一方面只在当前任务队列为空时才转为 worker，另一方面有定时的check_stall 线程来保底。但如差异二中看到的，还是会造成任务执行的延时<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>。</p>
<p>再例如能不能只用一个 queue？早期的实现其实就没有区分高优低优队列，Percona 后来实现优先队列是为了缩短服务端内部的 XA 事务<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>。对表锁的高优操作也是后来才添加的。</p>
<p>还有为什么不在创建线程时就限制总数不能超过 oversubscribed？（以下是猜想）
oversubscribe 从设计来看<strong>不应该</strong>是一个硬限制，它要达到的目的是在全局限制线程数的前提下，防止某个 thread group 疯狂创建吃掉所有限额，造成其它 group 创建不了线程的情况。但是适当允许某个 group 创建超过 oversubscribe 的线程数是有助于提高整体效率的。而且绝对限死线程数也更可能造成 group 内的死锁，保持弹性能应对更多异常的情况。</p>
<h2 id="参考"><a class="header-anchor" href="#参考"></a>参考</h2>
<ul>
<li><a href="https://docs.percona.com/percona-server/8.0/performance/threadpool.html">Percona thread pool</a> 对 threadpool 的行为有一些说明，但并不是很全面</li>
<li>添加 debug 信息的源码文件，有兴趣的可以自己编译验证
<ul>
<li>
<a href="/2023/Verification-of-Percona-Thread-Pool-Behavior/threadpool_unix.cc" title="threadpool_unix.cc">threadpool_unix.cc</a> 
</li>
<li>
<a href="/2023/Verification-of-Percona-Thread-Pool-Behavior/sql_parse.cc" title="sql_parse.cc">sql_parse.cc</a> 
</li>
</ul>
</li>
<li><a href="https://mariadb.com/kb/en/thread-groups-in-the-unix-implementation-of-the-thread-pool/">MySQL 线程组实现文档</a> oversubscribed 实现不同，但其它的如线程创建方面可以参考</li>
</ul>
<p>另外关于 Percona 线程机制的描述一搜一大把，可以结合本文案例理解。</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>参考 <a href="https://github.com/percona/percona-server/blob/8.0/sql/threadpool_unix.cc#L390">connection_is_high_prio</a>
中定义了各种条件。除了要满足条件，Percona 会给每个 connection 发放 N 个高优的 ticket，只有ticket 有剩余，其中的 SQL 才会认为是高优。另外除了默认的
transactions 模式，还有 statement 模式，则每个 statement 都认为是高优。 <a href="#fnref1" class="footnote-backref">↩</a></p>
</li>
<li id="fn2" class="footnote-item"><p>参考原代码的注释 <a href="https://github.com/percona/percona-server/blob/8.0/sql/threadpool_unix.cc#L656">https://github.com/percona/percona-server/blob/8.0/sql/threadpool_unix.cc#L656</a> <a href="#fnref2" class="footnote-backref">↩</a></p>
</li>
<li id="fn3" class="footnote-item"><p><a href="https://github.com/percona/percona-server/commit/5be2144799ced62217f252b0cb0dd9917784e868">这个 commit</a>
提到目标是 “minimize the number of open transactions in the server”，结合代码看到 open transactions 指的是 XA 的事务。 <a href="#fnref3" class="footnote-backref">↩</a></p>
</li>
</ol>
</section>
</div></div><div class="post-main post-comment"><div id="giscus_thread"></div><script src="https://giscus.app/client.js" data-repo="lotabout/lotabout.github.io" data-repo-id="MDEwOlJlcG9zaXRvcnkyMDU1NTQ0Nw==" data-category="Announcements" data-category-id="DIC_kwDOATmmt84ClmcD" data-mapping="" data-strict="" data-reactions-enabled="0" data-emit-metadata="" data-input-position="" data-theme="" data-lang="zh-CN" data-loading="" crossorigin="" async>
</script></div></article><link rel="stylesheet" type="text/css" href="/css/third-party/font-awesome/4.5.0/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcdn.net/ajax/libs/lato-font/3.0.0/css/lato-font.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcdn.net/ajax/libs/fancybox/2.1.5/jquery.fancybox.css"><script src="/js/third-party/jquery/2.0.3/jquery.min.js"></script><script src="/js/third-party/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
  $(".fancybox").fancybox();
});
</script><script async src="https://www.googletagmanager.com/gtag/js?id=#{theme.google_analytics}"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-39956831-2');</script></body></html>