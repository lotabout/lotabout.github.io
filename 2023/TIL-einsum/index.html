<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="很多复杂的矩阵计算可以使用 einsum 来表示，方便 PoC，性能也还过得去。"><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/noise.css"><title>TIL: 使用 einsum 进行复杂的矩阵计算 | 三点水</title><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><meta name="generator" content="Hexo 7.1.1"></head><body><article class="wrapper"><div class="post-main"><div class="nav"><nav class="container"><a class="sidebar-nav-item active" href="/">Home</a><a class="sidebar-nav-item" href="/books">Books</a><a class="sidebar-nav-item" href="/about">About</a></nav><div class="container post-meta"><div class="post-tags"><a class="post-tag-noise-link" href="/tags/TIL/" rel="tag">TIL</a><a class="post-tag-noise-link" href="/tags/einsum/" rel="tag">einsum</a><a class="post-tag-noise-link" href="/tags/numpy/" rel="tag">numpy</a><a class="post-tag-noise-link" href="/tags/torch/" rel="tag">torch</a></div><div class="post-time">2023-05-01</div></div></div><div class="container post-header"><h1>TIL: 使用 einsum 进行复杂的矩阵计算</h1></div><div class="container post-toc"><details class="toc"><summary class="toc-accordion">Table of Contents</summary><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#einstein-notation"><span class="toc-number">1.</span> <span class="toc-text">Einstein notation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#einsum"><span class="toc-number">2.</span> <span class="toc-text">Einsum</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%8D%E6%9D%82%E5%BA%94%E7%94%A8"><span class="toc-number">3.</span> <span class="toc-text">复杂应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%A7%E8%83%BD"><span class="toc-number">4.</span> <span class="toc-text">性能</span></a></li></ol></details></div><div class="container post-content"><p>很多复杂的矩阵计算可以使用 einsum 来表示，方便 PoC，性能也还过得去。</p>
<h2 id="einstein-notation"><a class="header-anchor" href="#einstein-notation"></a>Einstein notation</h2>
<p>你没有看错，<a href="https://en.wikipedia.org/wiki/Einstein_notation">Einstein notation</a>
是那位著名的爱因斯坦发明的，用来对线性代数中求和的表示做的约定。我们还是看个例子<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>：</p>
<p>$$
y = \sum_{i=1}^{3}{c_i x_i} = c_1 x_1 + c_2 x_2 + c_3 x_3
$$</p>
<p>如果一个下标（如 $i$）在公式中出现两次，则隐式地认为需要遍历它的所有可能性。上面公式可以简化成：</p>
<p>$$
y = c_i x_i
$$</p>
<p>于是矩阵乘法中，每个输出元素可以这样表示：</p>
<p>$$
c_{ij} = \sum_{k}{a_{ik} b_{kj}} \implies c_{ik} = a_{ik} b_{kj}
$$</p>
<h2 id="einsum"><a class="header-anchor" href="#einsum"></a>Einsum</h2>
<p>在 <a href="https://numpy.org/doc/stable/reference/generated/numpy.einsum.html">Numpy</a>
和 <a href="https://pytorch.org/docs/stable/generated/torch.einsum.html">Pytorch</a> 中都实现了类似的机制。<code>einsum</code> 函数的第一个参数就是把上节公式中的各个下标按
<code>a,b-&gt;c</code> 的格式写下来：</p>
<img src="/2023/TIL-einsum/2023-05-einsum.svg" class="" title="Einsum subscript illustration">
<p>代码实例如下：</p>
<div class="noise-code-block" style="--code-block-max-height:inherit"><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">6</span>]: a = np.asarray(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">9</span>)).reshape(<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: a</span><br><span class="line">Out[<span class="number">7</span>]:</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">8</span>]: b = np.asarray(<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">9</span>)).reshape(<span class="number">4</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">9</span>]: b</span><br><span class="line">Out[<span class="number">9</span>]:</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">10</span>]: a @ b</span><br><span class="line">Out[<span class="number">10</span>]:</span><br><span class="line">array([[ <span class="number">50</span>,  <span class="number">60</span>],</span><br><span class="line">       [<span class="number">114</span>, <span class="number">140</span>]])</span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: np.einsum(<span class="string">&#x27;ik,kj-&gt;ij&#x27;</span>, a, b)</span><br><span class="line">Out[<span class="number">11</span>]:</span><br><span class="line">array([[ <span class="number">50</span>,  <span class="number">60</span>],</span><br><span class="line">       [<span class="number">114</span>, <span class="number">140</span>]])</span><br></pre></td></tr></table></figure></div>
<h2 id="复杂应用"><a class="header-anchor" href="#复杂应用"></a>复杂应用</h2>
<p>例如在 CNN 求卷积时，输入是 <code>(n, c, ih, iw)</code> 的矩阵，卷积权重是 <code>(C, c, h, w)</code>（这里大写字母代表输出维度）。可以把原图像按卷积大小的各个子图求出，得到 <code>(n, c, H, W, h, w)</code> 的输入矩阵，于是可以使用 einsum 直接求结果：</p>
<div class="noise-code-block" style="--code-block-max-height:inherit"><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">conv2d</span>(<span class="params">x, weight, stride=(<span class="params"><span class="number">1</span>,<span class="number">1</span></span>), padding=(<span class="params"><span class="number">0</span>,<span class="number">0</span></span>)</span>):</span><br><span class="line">    <span class="comment"># x is a 4d matrix (n, c, ih, iw), where n is batchsize, c is input channel</span></span><br><span class="line">    <span class="comment"># weight is a 4d matrix (oc, c, h, w), where o_c is output channel</span></span><br><span class="line">    <span class="comment"># out is (n, oc, h, w)</span></span><br><span class="line">    <span class="keyword">if</span> padding != (<span class="number">0</span>,<span class="number">0</span>):</span><br><span class="line">        p_h, p_w = padding</span><br><span class="line">        x_padded = np.pad(x, ((<span class="number">0</span>,<span class="number">0</span>), (<span class="number">0</span>,<span class="number">0</span>), (p_h,p_h), (p_w, p_w)))</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        x_padded = x</span><br><span class="line"></span><br><span class="line">    i_n, i_c, i_h, i_w = x_padded.shape</span><br><span class="line">    s_h, s_w = stride</span><br><span class="line">    wo_c, wi_c, w_h, w_w = weight.shape</span><br><span class="line"></span><br><span class="line">    o_n = i_n</span><br><span class="line">    o_c = wo_c</span><br><span class="line">    o_h = (i_h - w_h) // s_h + <span class="number">1</span></span><br><span class="line">    o_w = (i_w - w_w) // s_w + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    view_shape = (i_n, i_c, o_h, o_w, w_h, w_w)</span><br><span class="line">    view_strides = np.array([(i_c*i_h*i_w), (i_h*i_w) , s_h*i_w, s_w, i_w, <span class="number">1</span>]) * x_padded.itemsize</span><br><span class="line">    submatrix = np.lib.stride_tricks.as_strided(x_padded, view_shape, view_strides)</span><br><span class="line">    <span class="keyword">return</span> np.einsum(<span class="string">&#x27;ncHWhw,Cchw-&gt;nCHW&#x27;</span>, submatrix, weight, optimize=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></div>
<p>看到 <code>ncHWhw,Cchw-&gt;nCHW</code> 的输入中，<code>c, h, w</code> 下标是重复的，按约定要遍历所有三个下标的元素相乘，要是裸写代码的话，类似下面这样：</p>
<div class="noise-code-block" style="--code-block-max-height:inherit"><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n,c,H,W,h,w = submatrix.shape</span><br><span class="line">C,c,h,w = weight.shape</span><br><span class="line"></span><br><span class="line">result = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> cc <span class="keyword">in</span> <span class="built_in">range</span>(c):</span><br><span class="line">    <span class="keyword">for</span> hh <span class="keyword">in</span> <span class="built_in">range</span>(h):</span><br><span class="line">        <span class="keyword">for</span> ww <span class="keyword">in</span> <span class="built_in">range</span>(w):</span><br><span class="line">            result += a[n, cc, H, W, hh, ww] * b[C, cc, hh, ww]</span><br><span class="line">out[n, C, H, W] = result</span><br></pre></td></tr></table></figure></div>
<h2 id="性能"><a class="header-anchor" href="#性能"></a>性能</h2>
<p>一般比裸写 for 循环是要快不少的（比如上面的卷积，比我自己裸写的快 3x~5x）。但比专门优化的肯定还是不能比的（pytorch 的 conv2d 是用 C++ 专门优化的，比相同的
einsum 快 10x）。</p>
<p>另外 <a href="https://zhuanlan.zhihu.com/p/71639781">这篇文章</a> 建议无脑开 Numpy 中的
<code>optimize</code> 参数。</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>wiki 中 $x_i$ 表示成 $x^i$，我们这里还是以普通人视角来看 <a href="#fnref1" class="footnote-backref">↩</a></p>
</li>
</ol>
</section>
</div></div><script type="text/x-mathjax-config">
   MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    }); 
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="https://cdn.bootcdn.net/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><div class="post-main post-comment"><div id="giscus_thread"></div><script src="https://giscus.app/client.js" data-repo="lotabout/lotabout.github.io" data-repo-id="MDEwOlJlcG9zaXRvcnkyMDU1NTQ0Nw==" data-category="Announcements" data-category-id="DIC_kwDOATmmt84ClmcD" data-mapping="" data-strict="" data-reactions-enabled="0" data-emit-metadata="" data-input-position="" data-theme="" data-lang="zh-CN" data-loading="" crossorigin="" async>
</script></div></article><link rel="stylesheet" type="text/css" href="/css/third-party/font-awesome/4.5.0/font-awesome.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcdn.net/ajax/libs/lato-font/3.0.0/css/lato-font.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcdn.net/ajax/libs/fancybox/2.1.5/jquery.fancybox.css"><script src="/js/third-party/jquery/2.0.3/jquery.min.js"></script><script src="/js/third-party/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
  $(".fancybox").fancybox();
});
</script><script async src="https://www.googletagmanager.com/gtag/js?id=#{theme.google_analytics}"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-39956831-2');</script></body></html>